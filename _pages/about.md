---
permalink: /
#layout: archive
excerpt: "About me"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

<span class="small_font">I am a MS by Research student at International Institute of Information Technology, Hyderabad (IIIT-H). I am advised by Professor <a target="_blank" href="https://faculty.iiit.ac.in/~jawahar/">C V Jawahar</a> and Professor <a target="_blank" href="https://vinaypn.github.io/">Vinay Namboodiri</a> at the Center for Visual Information Technology (CVIT) Lab. I am also advised by Professor <a target="_blank" href="https://www.iiit.ac.in/people/faculty/mkrishna/">K. Madhav Krishna</a> and Professor <a target="_blank" href="https://cs.brown.edu/people/ssrinath/">Srinath Sridhar</a> at the Robotics Research Center (RRC). </span>

<span class="small_font">Before IIIT-H, I was a Data Scientist at Microsoft Research & Development, Hyderabad. I led the recommendation and suggestion team for the world's biggest enterprise facing email client - Outlook. These features are used by more than 100 million users per month, my hunch is that you might have seen some of them! <img class="tiny-emoji" with="18px" src="images/grin.svg">
</span>

<span class="small_font">I am also a musician, I sing and play guitar. I have toured and performed at several places with my previous band, <a target="_blank" href="https://www.facebook.com/AndroMetaBand">Andrometa</a>. I also tried my hands out travel vlogging and YouTubing! My brother is a (really awesome) piano player and has taken over the channel now - find them <a target="_blank" href="https://www.youtube.com/channel/UCU1TMnEt0J1UJZfMW1Gixgg?view_as=subscriber" target="_blank">here!</a>. I also love traveling.</span>

<span class="small_font">In 2018, I travelled solo to 6 countries, 13 states and interviewed 128 independent musicians!</span>

<h3>Research Interest</h3>

<span class="small_font">My interest lies at the intesection of 3D computer vision and Robotics. Specifically, I am interested in designing improved representations of the 3D world that can enable an embodied agent acquire a holistic view of the world. Using this view, the embodied agent can take better control descisions in the downstream tasks, for example manipulation or navigation.  Ultimately, I am excited to see embodied AI become a part of the real-world and seamlessly integrate with the humans!</span>

<h3>Connect</h3>
<a href="https://twitter.com/NerdNess3195?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow @TwitterDev</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><br>
You can also reach out to me at bipasha dot sen at research dot iiit dot ac dot in. 

<div class="recent_updates">Recent Updates</div>

<ul class="updates">
	<li><b>JANUARY 2023:</b> I will be attending <a target="_blank" href="https://sites.google.com/view/researchweek2023/home">Google Research Week</a>!</li>
	<li><b>DECEMBER 2022:</b> Presented INR-V at <a target="_blank" href="https://events.iitgn.ac.in/2022/icvgip/vision_india.html">Vision India, Indian Conference on Computer Vision, Graphics and Image Processing (ICVGIP)</a>!<a target="_blank" class="tab_paper" href="https://iiitaphyd-my.sharepoint.com/:p:/g/personal/bipasha_sen_research_iiit_ac_in/EY4XFO4EOvtDonHHIxuy-BkBDirnrqLDGOe7V9rd2xJL7g?e=5npSCQ">presentation</a></li>
	<li><b>OCTOBER 2022:</b><br>INR-V: A Continuous Representation Space for Video-based Generative Tasks accepted at <b>TMLR 2022</b>!</li>
	<li><b>SEPTEMBER 2022:</b><br>I am grateful to Microsoft Research for awarding me a travel grant of $2000 for <b>WACV 2023</b>!</li>
	<li><b>AUGUST 2022:</b><br>1. 2 papers accepted at <b>WACV 2023</b>!<br>2. Gave a tutorial on "Computer Vision challenges in Table-top rearrangement and Planning" at the <a target="_blank" href="https://cvit.iiit.ac.in/summerschool2022/">6<sup>th</sup> Summer School of AI</a>, IIIT-H!<a target="_blank" class="tab_paper" href="blog#ttrp-talk">talk</a></li>
	<li><b>JUNE 2022:</b> We are in <a target="_blank" href="https://www.iiit.ac.in/files/media/Sakshi-RRC.jpeg">news</a>!</li>
	<li><b>APRIL 2022:</b> We came 3<sup>rd</sup> in <a target="_blank" href="http://ocrtoc.org/"><b>ICRA 2022</b> Open Cloud Robot Table Organization Challenge</a>!</li>
	<li><b>DECEMBER 2021:</b><br>Granted a Provisional Patent on "SYSTEM AND METHOD FOR TRAINING USERS TO LIP READ"!</li>
	<li><b>NOVEMBER 2021:</b> Joined Robotics Research Center as a Research Fellow!</li>
	<li><b>AUGUST 2021:</b> Joined MS by Research at IIIT-H!</li>
	<li><b>JUNE 2021:</b> "<a target="_blank" href="https://www.bmvc2021-virtualconference.com/assets/papers/1468.pdf">Personalized One-Shot Lipreading for an ALS Patient</a>" accepted at <b>BMVC 2021</b>!</li>
	<li><b>MARCH 2021:</b> Joined Center for Visual Information Technology as a Research Fellow!</li>
</ul>

<div class="recent_updates">Selected Research in MS</div>

<div class="research-block">
	<div class="left">
		<span class="research-img">
			<img src="/images/teasers/scarp_banner.gif">
		</span>
	</div>
	<div class="right">
		<div class="title">SCARP: 3D <b>S</b>hape <b>C</b>ompletion in <b>AR</b>bitrary <b>P</b>oses for Improved Grasping</div>
		<div class="sub-title"><b>Bipasha Sen*</b>, Aditya Agarwal*, Gaurav Singh*, Brojeshwar Bhowmick, Srinath Sridhar, Madhava Krishna, <i><b>Under Review @ ICRA 2023</b></i>,<a target="_blank" class="tab_paper" href="https://bipashasen.github.io/scarp/">project page</a><a target="_blank" class="tab_paper" href="https://www.youtube.com/watch?v=o2PuRVZ3jJA">video</a></div>
		<span class="research-text">
		We propose SCARP, a model that performs Shape Completion in ARbitrary Poses. Given a partial pointcloud of an object, SCARP learns a disentangled feature representation of pose and shape by relying on rotationally equivariant pose features and geometric shape features trained using a multi-tasking objective. 
		</span>
	</div>
</div>

<div class="research-block">
	<div class="left">
		<span class="research-img">
			<img src="/images/teasers/inr-v.gif">
		</span>
	</div>
	<div class="right">
		<div class="title">INR-V: A Continuous Representation Space for Video-based Generative Tasks</div>
		<div class="sub-title"><b>Bipasha Sen*</b>, Aditya Agarwal*, Vinay Namboodiri, C V Jawahar, <i><b>TMLR 2022</b></i>,<a target="_blank"  class="tab_paper" href="https://openreview.net/forum?id=aIoEkwc2oB&referrer=%5BTMLR%5D(%2Fgroup%3Fid%3DTMLR)">OpenReview</a><a target="_blank" class="tab_paper" href="https://skymanaditya1.github.io/INRV/">project page</a><a target="_blank" class="tab_paper" href="https://youtu.be/ViIwnu5vcck">video</a></div>
		<span class="research-text">
		We propose INR-V, a video representation network that learns a continuous space for video-based generative tasks. INR-V parameterizes videos using implicit neural representations (INRs), a multi-layered perceptron that predicts an RGB value for each input pixel location of the video.
		</span>
	</div>
</div>

<div class="research-block">
	<div class="left">
		<span class="research-img">
			<img src="/images/teasers/faceoff.gif">
		</span>
	</div>
	<div class="right">
		<div class="title">FaceOff: A Video-to-Video Face Swapping System</div>
		<div class="sub-title">Aditya Agarwal*, <b>Bipasha Sen*</b>, Rudrabha Mukhopadhyay, Vinay Namboodiri, C V Jawahar, <i><b>WACV 2023</b></i>,<a target="_blank" class="tab_paper"  href="https://openaccess.thecvf.com/content/WACV2023/html/Agarwal_FaceOff_A_Video-to-Video_Face_Swapping_System_WACV_2023_paper.html">paper</a><a target="_blank" class="tab_paper" href="https://www.youtube.com/watch?v=3TCugwmMjzo&t=2s">video</a> </div>
		<span class="research-text">
		We introduce video-to-video (V2V) face-swapping, a novel task of face-swapping that can preserve (1) the identity and expressions of the source (actor) face video and (2) the background and pose of the target (double) video. We propose FaceOff, a V2V face-swapping system that operates by learning a robust blending operation to merge two face videos following the constraints above. 
		</span>
	</div>
</div>

<div class="research-block">
	<div class="left">
		<span class="research-img">
			<img src="/images/teasers/lipreading.gif">
		</span>
	</div>
	<div class="right">
		<div class="title">Towards MOOCs for Lipreading: Using Synthetic Talking Heads to Train Humans in Lipreading at Scale</div>
		<div class="sub-title">Aditya Agarwal*, <b>Bipasha Sen*</b>, Rudrabha Mukhopadhyay, Vinay Namboodiri, C V Jawahar, <i><b>WACV 2023</b></i>,<a target="_blank" class="tab_paper" class="tab_paper" href="https://openaccess.thecvf.com/content/WACV2023/html/Agarwal_Towards_MOOCs_for_Lipreading_Using_Synthetic_Talking_Heads_To_Train_WACV_2023_paper.html">paper</a></div>
		<span class="research-text">
		We propose an end-to-end automated pipeline to a lipreading training platform using state-of-the-art talking heading video generator networks, text-to-speech models, and computer vision techniques. We then perform an extensive human evaluation using carefully thought out lipreading exercises to validate the quality of our designed platform against the existing lipreading platforms. 
		</span>
	</div>
</div>


<div class="research-block">
	<div class="left">
		<span class="research-img">
			<img src="/images/teasers/ocrtoc.gif">
		</span>
	</div>
	<div class="right">
		<div class="title">Approaches and Challenges in Robotic Perception for Table-top Rearrangement and Planning</div>
		<div class="sub-title">Aditya Agarwal*, <b>Bipasha Sen</b>*, Shankara Narayanan V*, Vishal Reddy Mandadi*, Brojeshwar Bhowmick, K Madhava Krishna, <i><b>Arxiv 2022</b></i>,<a target="_blank" class="tab_paper" href="https://arxiv.org/abs/2205.04090">paper</a><a target="_blank" class="tab_paper" href="https://youtu.be/GrOXEmwzxlA">video</a></div>
		<div class="win"><img src="images/trophy-icon.webp" width="10px">3rd in <a class="prize" href="https://rpal.cse.usf.edu/rgmc_icra2022/">ICRA 2022 Open Cloud Robot Table Organization Challenge</a></div>
		<span class="research-text">
		Table-top Rearrangement and Planning is a challenging problem that relies heavily on an excellent perception stack. We present a comprehensive overview and discuss the different challenges associated with the perception module. This work is a result of our extensive involvement in the ICRA 2022 OCRTOC Challenge.
		</span>
	</div>
</div>

<div class="research-block">
	<div class="left">
		<span class="research-img">
			<img src="/images/teasers/personalized.gif">
		</span>
	</div>
	<div class="right">
		<div class="title">Personalized One-Shot Lipreading for an ALS Patient</div>
		<div class="sub-title"><b>Bipasha Sen</b>*, Aditya Agarwal*, Rudrabha Mukhopadhyay, Vinay Namboodiri, C V Jawahar, <i><b>BMVC 2021</b></i>,<a class="tab_paper" target="_blank" href="https://www.bmvc2021-virtualconference.com/assets/papers/1468.pdf">paper</a><a target="_blank"  class="tab_paper" href="https://youtu.be/_famGVaem-8">video</a><a target="_blank"  class="tab_paper" href="http://bhaasha.iiit.ac.in/lipwav">portal</a></div>
		<span class="research-text">
		We propose a personalized network to lipread an ALS patient using only one-shot examples. Our approach significantly improves and achieves high top-5accuracy with 83.2% accuracy compared to 62.6% achieved by comparable methods for the patient. Apart from evaluating our approach on the ALS patient, we also extend it to people with hearing impairment relying extensively on lip movements to communicate.
		</span>
	</div>
</div>
